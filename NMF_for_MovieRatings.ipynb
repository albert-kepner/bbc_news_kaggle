{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83395196",
   "metadata": {},
   "source": [
    "# NMF_for_MovieRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c7593d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uID</th>\n",
       "      <th>mID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2233</td>\n",
       "      <td>440</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4274</td>\n",
       "      <td>587</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2498</td>\n",
       "      <td>454</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2868</td>\n",
       "      <td>2336</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1636</td>\n",
       "      <td>2686</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300058</th>\n",
       "      <td>810</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300059</th>\n",
       "      <td>1193</td>\n",
       "      <td>3210</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300060</th>\n",
       "      <td>6039</td>\n",
       "      <td>2289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300061</th>\n",
       "      <td>5397</td>\n",
       "      <td>429</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300062</th>\n",
       "      <td>1912</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300063 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uID   mID  rating\n",
       "0       2233   440       4\n",
       "1       4274   587       5\n",
       "2       2498   454       3\n",
       "3       2868  2336       5\n",
       "4       1636  2686       5\n",
       "...      ...   ...     ...\n",
       "300058   810   247       4\n",
       "300059  1193  3210       4\n",
       "300060  6039  2289       4\n",
       "300061  5397   429       3\n",
       "300062  1912   117       4\n",
       "\n",
       "[300063 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import coo_matrix, csr_matrix\n",
    "from scipy.spatial.distance import jaccard, cosine \n",
    "from pytest import approx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "MV_users = pd.read_csv('data/users.csv')\n",
    "MV_movies = pd.read_csv('data/movies.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "from collections import namedtuple\n",
    "Data = namedtuple('Data', ['users','movies','train','test'])\n",
    "data = Data(MV_users, MV_movies, train, test)\n",
    "display(data.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3e6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.allusers = list(self.data.users['uID'])\n",
    "        self.allmovies = list(self.data.movies['mID'])\n",
    "        self.genres = list(self.data.movies.columns.drop(['mID', 'title', 'year']))\n",
    "        self.mid2idx = dict(zip(self.data.movies.mID,list(range(len(self.data.movies)))))\n",
    "        self.uid2idx = dict(zip(self.data.users.uID,list(range(len(self.data.users)))))\n",
    "        self.Mr=self.rating_matrix()\n",
    "        self.Mm=None \n",
    "        self.sim=np.zeros((len(self.allmovies),len(self.allmovies)))\n",
    "        self.movies_rated_by_dict = self.train_movies_rated()\n",
    "        self.avg_user_ratings, self.avg_user_rating_array = self.get_avg_user_ratings()\n",
    "         \n",
    "        \n",
    "    def get_avg_user_ratings(self):\n",
    "        \"\"\"\n",
    "        For each unique uid, add to a dictionary the average ratings for movies rated by that user.\n",
    "        Return a dictionary and and array, with respective keys of uid and user index.\n",
    "        \"\"\"\n",
    "        df2 = self.data.train[['uID','rating']].groupby('uID',as_index=False).mean()\n",
    "        dict1 = {uid: rating for uid, rating in df2.itertuples(index=False, name=None)}\n",
    "        dict2 = {self.uid2idx[uid]: rating for uid, rating in df2.itertuples(index=False, name=None)}\n",
    "        arr = np.zeros(len(self.data.users))\n",
    "        for i in range(len(self.data.users)):\n",
    "            arr[i] = dict2[i]\n",
    "        return dict1, arr\n",
    "        \n",
    "    def train_movies_rated(self):\n",
    "        \"\"\"\n",
    "        For each unique uid, construct a list of movie INDEXES rated by that user.\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        df2 = self.data.train.drop(['rating'],axis=1)\n",
    "        for uid, mid in df2.itertuples(index=False, name=None):\n",
    "            midx = self.mid2idx[mid]\n",
    "            if uid not in d:\n",
    "                d[uid] = []\n",
    "            d[uid].append(midx)\n",
    "        return d\n",
    "        \n",
    "    def rating_matrix(self):\n",
    "        \"\"\"\n",
    "        Convert the rating matrix to numpy array of shape (#allusers,#allmovies)\n",
    "        \"\"\"\n",
    "        ind_movie = [self.mid2idx[x] for x in self.data.train.mID] \n",
    "        ind_user = [self.uid2idx[x] for x in self.data.train.uID]\n",
    "        rating_train = list(train.rating)\n",
    "        return np.array(coo_matrix((rating_train, \n",
    "                                    (ind_user, ind_movie)), shape=(len(self.allusers), len(self.allmovies))).toarray())\n",
    "\n",
    "    def predict_everything_to_3(self):\n",
    "        \"\"\"\n",
    "        Predict everything to 3 for the test data\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        return np.array([3] * self.data.test.shape[0])\n",
    "        \n",
    "        \n",
    "    def predict_to_user_average(self):\n",
    "        \"\"\"\n",
    "        Predict to average rating for the user.\n",
    "        Returns numpy array of shape (#users,)\n",
    "        \"\"\"\n",
    "        n_test = self.data.test.shape[0]\n",
    "        predictions = np.zeros(n_test)\n",
    "        df = self.data.test\n",
    "        for idx, uid in enumerate(list(df['uID'])):\n",
    "            predictions[idx] = self.avg_user_ratings[uid]\n",
    "        return predictions\n",
    "    \n",
    "    def predict_from_sim(self,uid,mid):\n",
    "        \"\"\"\n",
    "        Predict a user rating on a movie given userID and movieID\n",
    "        \"\"\"\n",
    "        ## For movies rated by this user in train\n",
    "        ## weight each rating by its similarity score relative to the target movie\n",
    "        uidx = self.uid2idx[uid]\n",
    "        m_target = self.mid2idx[mid]\n",
    "        movies_rated = self.movies_rated_by_dict[uid]        \n",
    "        ratings = [ self.Mr[uidx,midx] for midx in movies_rated]\n",
    "        similarity = [self.sim[m_target,midx]  for midx in movies_rated]\n",
    "        weighted_scores = np.dot(ratings, similarity)\n",
    "        numerator = np.sum(weighted_scores)\n",
    "        denominator = np.sum(similarity)\n",
    "        if denominator > 0:\n",
    "            prediction = numerator / denominator\n",
    "        else:\n",
    "            prediction = self.avg_user_ratings[uid]\n",
    "        return prediction\n",
    "        \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        n_test = self.data.test.shape[0]\n",
    "        predictions = np.zeros(n_test)\n",
    "        df = self.data.test\n",
    "        for idx, (uid, mid) in enumerate(df[['uID','mID']].itertuples(index=False, name=None)):\n",
    "            prediction = self.predict_from_sim(uid, mid)\n",
    "            predictions[idx] = prediction\n",
    "        return predictions\n",
    "    \n",
    "    def rmse(self,yp):\n",
    "        yp[np.isnan(yp)]=3 #In case there is nan values in prediction, it will impute to 3.\n",
    "        yt=np.array(self.data.test.rating)\n",
    "        return np.sqrt(((yt-yp)**2).mean())\n",
    "\n",
    "    \n",
    "class ContentBased(RecSys):\n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        self.data=data\n",
    "        self.Mm = self.calc_movie_feature_matrix()\n",
    "       \n",
    "        \n",
    "    def calc_movie_feature_matrix(self):\n",
    "        \"\"\"\n",
    "        Create movie feature matrix in a numpy array of shape (#allmovies, #genres) \n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        df = self.data.movies\n",
    "        df2 = df.drop(columns=['mID','title','year'])\n",
    "        return df2.to_numpy()\n",
    "\n",
    "    def jaccard(self, sa, sb):\n",
    "        \"\"\"\n",
    "        calculate Jaccard similarity for two binary vectors\n",
    "        which represent the movie genres present in two movies being compared.\n",
    "        \"\"\"\n",
    "        return sum(sa & sb)/sum(sa | sb)\n",
    "    \n",
    "    def calc_item_item_similarity(self):\n",
    "        \"\"\"\n",
    "        Create item-item similarity using Jaccard similarity\n",
    "        \"\"\"\n",
    "        n = self.Mm.shape[0]\n",
    "        print(f'n = number of Movies = {n}')\n",
    "        for i in range(n):\n",
    "            movie_i = self.Mm[i,:]\n",
    "            for j in range(i,n):\n",
    "                movie_j = self.Mm[j,:]\n",
    "                sim_score = self.jaccard(movie_i, movie_j)\n",
    "                ## jaccard similarity between any 2 movies \n",
    "                ## leads to a symmetric matix\n",
    "                self.sim[i,j] = sim_score\n",
    "                self.sim[j,i] = sim_score\n",
    "                \n",
    "class Collaborative(RecSys):    \n",
    "    def __init__(self,data):\n",
    "        super().__init__(data)\n",
    "        self.X = self.impute_missing_ratings()\n",
    "        \n",
    "    def impute_missing_ratings(self):\n",
    "        rows = self.Mr.shape[0]\n",
    "        cols = self.Mr.shape[1]\n",
    "        X = np.zeros((rows,cols))\n",
    "        for uidx in range(rows):\n",
    "            user_avg_rating = self.avg_user_rating_array[uidx]\n",
    "            for midx in range(cols):\n",
    "                X[uidx, midx] = self.Mr[uidx, midx]\n",
    "                if not self.Mr[uidx, midx]:\n",
    "                    X[uidx, midx] = user_avg_rating\n",
    "        X = X - self.avg_user_rating_array[:, np.newaxis]\n",
    "        return X\n",
    "                \n",
    "        \n",
    "    def calc_item_item_similarity(self, simfunction, *X):  \n",
    "        \"\"\"\n",
    "        Create item-item similarity using similarity function. \n",
    "        X is an optional transformed matrix of Mr\n",
    "        \"\"\"    \n",
    "        if len(X)==0:\n",
    "            self.sim = simfunction()            \n",
    "        else:\n",
    "            self.sim = simfunction(X[0]) # *X passes in a tuple format of (X,), to X[0] will be the actual transformed matrix\n",
    "            \n",
    "    def cossim(self):    \n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using cosine similarity (values from 0 to 1) on utility matrix\n",
    "        Returns a cosine similarity matrix of size (#all movies, #all movies)\n",
    "        \"\"\"\n",
    "        #         **To Do:**    \n",
    "        # 1.Impute the unrated entries in self.Mr to the user's average rating \n",
    "        # then subtract by the user mean, call this matrix X.   \n",
    "        # 2.Calculate cosine similarity for all item-item pairs. \n",
    "        # Don't forget to rescale the cosine similarity to be 0~1.    \n",
    "        # You might encounter divide by zero warning (numpy will fill nan value for that entry). \n",
    "        # In that case, you can fill those with appropriate values.\n",
    "        \n",
    "        self.pdist = pdist(self.X.T, metric='cosine')\n",
    "        self.squareform = squareform(self.pdist)\n",
    "        self.cosine_raw = -1 * self.squareform + 1\n",
    "        self.cosine_raw = np.nan_to_num(self.cosine_raw)\n",
    "        self.cosine = 0.5 + 0.5 * self.cosine_raw\n",
    "        return self.cosine\n",
    "    \n",
    "    def jacsim(self,Xr):\n",
    "        \"\"\"\n",
    "        Calculates item-item similarity for all pairs of items using jaccard similarity (values from 0 to 1)\n",
    "        Xr is the transformed rating matrix.\n",
    "        \"\"\"     \n",
    "        self.jac_pdist = pdist(Xr.T, metric='jaccard')\n",
    "        self.jac_squareform = squareform(self.jac_pdist)\n",
    "        self.jaccard = -1 * self.jac_squareform + 1\n",
    "        return self.jaccard\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce112f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2585510334053043\n"
     ]
    }
   ],
   "source": [
    "# tests predict_everything_to_3 in class RecSys\n",
    "rs = RecSys(data)\n",
    "yp = rs.predict_everything_to_3()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c62e7135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0352910334228647\n"
     ]
    }
   ],
   "source": [
    "# tests predict_to_user_average in the class RecSys\n",
    "yp = rs.predict_to_user_average()\n",
    "print(rs.rmse(yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49db9230",
   "metadata": {},
   "source": [
    "## For comparison with NMF this is the best prediction RMSE for item to item similarity using the methods from Homework 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5582ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity calculation time 206.0671339999999\n",
      "0.9509147941162469\n",
      "CPU times: total: 4min 28s\n",
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cf = Collaborative(data)\n",
    "Xr = cf.Mr.astype(int)\n",
    "t0=time.perf_counter()\n",
    "cf.calc_item_item_similarity(cf.jacsim,Xr)\n",
    "t1=time.perf_counter()\n",
    "time_sim = t1-t0\n",
    "print('similarity calculation time',time_sim)\n",
    "yp = cf.predict()\n",
    "rmse = cf.rmse(yp)\n",
    "print(rmse)\n",
    "assert(rmse<0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6142fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.Mr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96717251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Doc',\n",
       " 'Com',\n",
       " 'Hor',\n",
       " 'Adv',\n",
       " 'Wes',\n",
       " 'Dra',\n",
       " 'Ani',\n",
       " 'War',\n",
       " 'Chi',\n",
       " 'Cri',\n",
       " 'Thr',\n",
       " 'Sci',\n",
       " 'Mys',\n",
       " 'Rom',\n",
       " 'Fil',\n",
       " 'Fan',\n",
       " 'Act',\n",
       " 'Mus']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd6c6018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cf.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d51e414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23453320"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.Mr.shape[0] * cf.Mr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a9d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c99bca34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5]),\n",
       " array([22753174,    39436,    75174,   182802,   244225,   158509],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cf.Mr, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8df8517b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proportion_of_missing_values=0.9701472542053747\n"
     ]
    }
   ],
   "source": [
    "proportion_of_missing_values = 22753174/23453320\n",
    "print(f'{proportion_of_missing_values=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864bfe7",
   "metadata": {},
   "source": [
    "## Imputing missing values in the Movie Rating Matrix\n",
    "\n",
    "We want to apply NMF matrix factorization to a matrix MovieRatings of #users by #movies which contains\n",
    "user ratings 1 to 5 for some of the movies. Missing ratings have been represented by zero. Note that about 97%\n",
    "of the values are missing. On average each user rated about 3% of the movies.\n",
    "We would like to factor this matrix to infer the genres of the movies on the theory that the genre\n",
    "weighting of the various movies is the main determiner of the user preference for the movies.\n",
    "So in theory we should be able to factor MovieRatings into the product of two matracies\n",
    "of dimensions #Users by #Genres and #Genres by #Movie.\n",
    "\n",
    "However we have a problem because the NMF method does not work with missing values. If we leave the missing values\n",
    "represented as zero, this would assume that most users have a very low opinion of most movies. I propose replacing\n",
    "all of the zero ratings by the average movie rating for each user, before we attempt the matrix factorization. This\n",
    "is still not a very good solution because it will weight any predicitions toward the average of user's ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb951cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3883)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Complete the Movie Ratings Matrix by replacing zeros with the average movie rating for each user.\n",
    "MovieRatings = cf.Mr\n",
    "MovieRatingsImputed = np.zeros(MovieRatings.shape)\n",
    "display(MovieRatings.shape)\n",
    "zero_count = 0\n",
    "for user_idx in range(MovieRatings.shape[0]):\n",
    "    for movie_idx in range(MovieRatings.shape[1]):\n",
    "        if MovieRatings[user_idx,movie_idx] == 0:\n",
    "            zero_count = zero_count + 1\n",
    "            MovieRatingsImputed[user_idx,movie_idx] = cf.avg_user_rating_array[user_idx]\n",
    "        else:\n",
    "            MovieRatingsImputed[user_idx,movie_idx] = MovieRatings[user_idx,movie_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea978b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.702782708415624"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(MovieRatingsImputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdb482",
   "metadata": {},
   "source": [
    "# Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21cf0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e7zv5qo\\Anaconda3\\envs\\TF_GPU_MTCNN\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1637: ConvergenceWarning: Maximum number of iterations 10000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape=(6040, 18)\n",
      "components.shape=(18, 3883)\n",
      "CPU times: total: 36min 43s\n",
      "Wall time: 6min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "MAX_NMF_ITERATIONS = 10000\n",
    "NUMBER_OF_CATEGORIES = 18 # number of Genres associated with movie ratings\n",
    "# Run the nmf model\n",
    "nmf = NMF(\n",
    "    n_components=NUMBER_OF_CATEGORIES, \n",
    "    init='nndsvd',\n",
    "    max_iter=MAX_NMF_ITERATIONS,\n",
    "    l1_ratio=0.0,\n",
    "    solver='cd',\n",
    "    alpha_W=0.0, \n",
    "    alpha_H='same',\n",
    "    tol=1e-5,\n",
    "    random_state=42\n",
    ").fit(MovieRatingsImputed)\n",
    "\n",
    "weights = nmf.transform(MovieRatingsImputed)\n",
    "components = nmf.components_\n",
    "print(f'{weights.shape=}')\n",
    "print(f'{components.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5579e2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_NMF_weights(user_weights, movie_components, user_idx, movie_idx):\n",
    "    \"\"\"\n",
    "    Predict user ratings for movies based on NMF factorization\n",
    "    \"\"\"\n",
    "    prediction = np.dot(user_weights[user_idx,:],movie_components[:,movie_idx])\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24895249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_NMF(rec_sys, user_weights, movie_components):\n",
    "    \"\"\"\n",
    "    Predict ratings in the test data. Returns predicted rating in a numpy array of size (# of rows in testdata,)\n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    n_test = rec_sys.data.test.shape[0]\n",
    "    predictions = np.zeros(n_test)\n",
    "    df = rec_sys.data.test\n",
    "    for idx, (uid, mid) in enumerate(df[['uID','mID']].itertuples(index=False, name=None)):\n",
    "        user_idx = rec_sys.uid2idx[uid]\n",
    "        movie_idx = rec_sys.mid2idx[mid]\n",
    "        prediction = predict_from_NMF_weights(user_weights, movie_components, user_idx, movie_idx)\n",
    "        predictions[idx] = prediction\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "185128f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9694834109776633\n"
     ]
    }
   ],
   "source": [
    "yp = predict_from_NMF(cf, weights, components)\n",
    "print(cf.rmse(yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2fe2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
